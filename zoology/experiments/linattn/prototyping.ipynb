{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = nn.LayerNorm(64)\n",
    "def ttt_inner_1_manual(W0_DxD, Q_TxD, K_TxD, V_TxD):\n",
    "    # y = ln(z), z = KW\n",
    "    Z_TxD = K_TxD @ W0_DxD\n",
    "    dy = ln(Z_TxD) - V_TxD\n",
    "    _, dz = torch.autograd.functional.vjp(lambda x: ln(x), Z_TxD, dy)\n",
    "    return torch.tril(Q_TxD @ K_TxD.T) @ (-dz)\n",
    "\n",
    "def ttt_inner_1_auto(W0_DxD, Q_TxD, K_TxD, V_TxD):\n",
    "    Ys = []\n",
    "    for i in range(Q_TxD.shape[0]):\n",
    "        loss_fn = lambda x_DxD: 0.5 * torch.sum((ln(K_TxD[:i+1] @ x_DxD) - V_TxD[:i+1]) ** 2)\n",
    "        dw_i = torch.func.grad(loss_fn)(W0_DxD)\n",
    "        Ys.append(Q_TxD[i] @ (-dw_i))\n",
    "    return torch.stack(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64\n",
    "X_TxD = torch.randn((100, D), requires_grad=True)\n",
    "QKVproj = nn.Linear(D, 3 * D)\n",
    "QKV_Tx3D = QKVproj(X_TxD)\n",
    "Q_TxD, K_TxD, V_TxD = torch.split(QKV_Tx3D, D, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008264871430583298, 0.01171875)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0_DxD = torch.zeros((D, D), device=K_TxD.device)\n",
    "out_auto = ttt_inner_1_auto(W0_DxD, Q_TxD, K_TxD, V_TxD)\n",
    "out_manual = ttt_inner_1_manual(W0_DxD, Q_TxD, K_TxD, V_TxD)\n",
    "torch.abs(out_auto - out_manual).mean().item(), torch.abs(out_auto - out_manual).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt_inner_2_manual(W0_DxD, Q_TxD, K_TxD, V_TxD):\n",
    "    # y = ln(z), z = KW\n",
    "    Z_TxD = K_TxD @ W0_DxD\n",
    "    dy = ln(Z_TxD) - V_TxD\n",
    "    dz1, = torch.func.vjp(ln, Z_TxD)[1](dy)\n",
    "\n",
    "    Z_TxD = Z_TxD - torch.tril(K_TxD @ K_TxD.T) @ dz1\n",
    "    dy = ln(Z_TxD) - V_TxD\n",
    "    dz2, = torch.func.vjp(ln, Z_TxD)[1](dy)\n",
    "\n",
    "    A_TxT = torch.tril(Q_TxD @ K_TxD.T)\n",
    "    return Q_TxD @ W0_DxD + A_TxT @ (-dz1) + A_TxT @ (-dz2)\n",
    "\n",
    "def ttt_inner_2_auto(W0_DxD, Q_TxD, K_TxD, V_TxD):\n",
    "    Ys = []\n",
    "    for i in range(Q_TxD.shape[0]):\n",
    "        loss_fn = lambda x_DxD: 0.5 * torch.sum((ln(K_TxD[:i+1] @ x_DxD) - V_TxD[:i+1]) ** 2)\n",
    "        dw_i = torch.func.grad(loss_fn)(W0_DxD)\n",
    "        W1_DxD = W0_DxD - dw_i\n",
    "        dw_i = torch.func.grad(loss_fn)(W1_DxD)\n",
    "        W2_DxD = W1_DxD - dw_i\n",
    "        Ys.append(Q_TxD[i] @ W2_DxD)\n",
    "    return torch.stack(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0_DxD = torch.zeros((D, D), device=K_TxD.device)\n",
    "out_auto = ttt_inner_1_auto(W0_DxD, Q_TxD, K_TxD, V_TxD)\n",
    "out_manual = ttt_inner_2_manual(W0_DxD, Q_TxD, K_TxD, V_TxD)\n",
    "(torch.abs(out_auto - out_manual) / torch.maximum(torch.abs(out_auto), torch.abs(out_manual))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoology_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
